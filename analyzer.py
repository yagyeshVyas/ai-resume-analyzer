"""
analyzer.py - AI-powered resume analysis using OpenRouter API
Supports 100+ models including free and paid options.
"""

import re
import json
import requests
import pdfplumber
from io import BytesIO


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# AVAILABLE MODELS ON OPENROUTER
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

FREE_MODELS = {
    # ‚îÄ‚îÄ üèÜ Best for Resume Analysis ‚îÄ‚îÄ
    "üèÜ Llama 3.3 70B ‚Äî Best for Resume (Recommended)":    "meta-llama/llama-3.3-70b-instruct:free",
    "üß† DeepSeek R1 0528 ‚Äî Best Reasoning":                "deepseek/deepseek-r1-0528:free",
    "‚ö° Mistral Small 3.1 24B ‚Äî Fast & Smart":             "mistralai/mistral-small-3.1-24b-instruct:free",
    "üåü Gemma 3 27B ‚Äî Google Model":                       "google/gemma-3-27b-it:free",

    # ‚îÄ‚îÄ ü§ñ Qwen Models ‚îÄ‚îÄ
    "üîµ Qwen3 Coder ‚Äî Best for Coding":                    "qwen/qwen3-coder:free",
    "üîµ Qwen3 4B ‚Äî Lightweight & Fast":                    "qwen/qwen3-4b:free",

    # ‚îÄ‚îÄ üü¢ Meta Llama Models ‚îÄ‚îÄ
    "üü¢ Llama 3.2 3B ‚Äî Fastest Free Model":               "meta-llama/llama-3.2-3b-instruct:free",
    "üü¢ Nous Hermes 3 Llama 405B ‚Äî Huge Model":           "nousresearch/hermes-3-llama-3.1-405b:free",

    # ‚îÄ‚îÄ üî¥ Google Models ‚îÄ‚îÄ
    "üî¥ Gemma 3 12B ‚Äî Google Balanced":                    "google/gemma-3-12b-it:free",
    "üî¥ Gemma 3 4B ‚Äî Google Lightweight":                  "google/gemma-3-4b-it:free",
    "üî¥ Gemma 3n E4B ‚Äî Google Nano":                       "google/gemma-3n-e4b-it:free",
    "üî¥ Gemma 3n E2B ‚Äî Google Ultra Nano":                 "google/gemma-3n-e2b-it:free",

    # ‚îÄ‚îÄ üü° NVIDIA Models ‚îÄ‚îÄ
    "üü° NVIDIA Nemotron 30B ‚Äî Powerful":                   "nvidia/nemotron-3-nano-30b-a3b:free",
    "üü° NVIDIA Nemotron 12B Vision ‚Äî Multimodal":          "nvidia/nemotron-nano-12b-v2-vl:free",
    "üü° NVIDIA Nemotron 9B ‚Äî Balanced":                    "nvidia/nemotron-nano-9b-v2:free",

    # ‚îÄ‚îÄ üü† OpenAI Open Source ‚îÄ‚îÄ
    "üü† OpenAI GPT-OSS 120B ‚Äî OpenAI Free":               "openai/gpt-oss-120b:free",
    "üü† OpenAI GPT-OSS 20B ‚Äî OpenAI Lightweight":         "openai/gpt-oss-20b:free",

    # ‚îÄ‚îÄ üü£ Other Models ‚îÄ‚îÄ
    "üü£ StepFun Step 3.5 Flash ‚Äî 256K Context":           "stepfun/step-3.5-flash:free",
    "üü£ Arcee Trinity Large ‚Äî Reasoning":                  "arcee-ai/trinity-large-preview:free",
    "üü£ Arcee Trinity Mini ‚Äî Lightweight":                  "arcee-ai/trinity-mini:free",
    "üü£ Solar Pro 3 ‚Äî Upstage Model":                      "upstage/solar-pro-3:free",
    "üü£ Z.AI GLM 4.5 Air ‚Äî 131K Context":                 "z-ai/glm-4.5-air:free",
    "üü£ Dolphin Mistral 24B ‚Äî Uncensored":                 "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
    "üü£ LiquidAI LFM 2.5 Thinking ‚Äî Reasoning":           "liquid/lfm-2.5-1.2b-thinking:free",
    "üü£ LiquidAI LFM 2.5 Instruct ‚Äî Fast":                "liquid/lfm-2.5-1.2b-instruct:free",

    # ‚îÄ‚îÄ üé≤ Auto Router ‚îÄ‚îÄ
    "üé≤ Auto Free Router ‚Äî Let OpenRouter Pick":           "openrouter/free",
}

PAID_MODELS = {
    "üëë Claude 3.5 Sonnet ‚Äî Best Overall":   "anthropic/claude-3.5-sonnet",
    "üíé GPT-4o ‚Äî Top Tier":                  "openai/gpt-4o",
    "üöÄ GPT-4o Mini ‚Äî Fast & Cheap":         "openai/gpt-4o-mini",
    "üåô Gemini 2.0 Flash ‚Äî Latest Google":   "google/gemini-2.0-flash-001",
    "üß¨ Claude 3 Haiku ‚Äî Fastest Paid":      "anthropic/claude-3-haiku",
    "üîÆ Llama 3.3 70B ‚Äî Best Open Source":   "meta-llama/llama-3.3-70b-instruct",
}

ALL_MODELS = {**FREE_MODELS, **PAID_MODELS}


def get_model_id(display_name: str) -> str:
    return ALL_MODELS.get(display_name, display_name)


def extract_text_from_pdf(uploaded_file) -> str:
    text = ""
    try:
        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        raise ValueError(f"Could not read PDF: {str(e)}")

    if not text.strip():
        raise ValueError("No text found in PDF. Make sure it's not a scanned image.")

    return text.strip()


def analyze_resume(api_key: str, model_id: str, resume_text: str,
                   job_description: str, job_title: str = "", company_name: str = "") -> dict:

    prompt = f"""You are an expert ATS (Applicant Tracking System) and career coach AI.
Analyze the following resume against the job description and provide a detailed evaluation.

JOB TITLE: {job_title or "Not specified"}
COMPANY: {company_name or "Not specified"}

RESUME:
{resume_text}

JOB DESCRIPTION:
{job_description}

Provide your analysis ONLY as valid JSON (no markdown, no extra text) in this exact format:
{{
  "ats_score": <integer 0-100, how well the resume will pass ATS systems>,
  "match_score": <integer 0-100, overall match to job requirements>,
  "matched_skills": [<list of skills/keywords found in both resume and JD>],
  "missing_skills": [<list of important skills/keywords in JD but missing from resume>],
  "strengths": [<3-5 specific strengths of this resume for this role>],
  "improvements": [<4-6 specific, actionable improvements the candidate should make>],
  "keyword_suggestions": [<5-8 exact keywords/phrases to add to resume for better ATS>],
  "experience_gap": "<brief analysis of experience level match>",
  "education_match": "<brief analysis of education requirements match>",
  "overall_summary": "<2-3 sentence honest assessment of this application chances>",
  "quick_wins": [<2-3 things they can fix in 10 minutes to immediately improve the resume>]
}}

Be specific, honest, and actionable."""

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://ai-resume-analyzer.streamlit.app",
        "X-Title": "AI Resume Analyzer"
    }

    payload = {
        "model": model_id,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 2000,
        "temperature": 0.3
    }

    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )

        if response.status_code == 401:
            raise ValueError("Invalid OpenRouter API key. Get a free key at: https://openrouter.ai/keys")
        elif response.status_code == 402:
            raise ValueError("Insufficient credits for this paid model. Use a free model or add credits at openrouter.ai")
        elif response.status_code == 429:
            raise ValueError("Rate limit hit. Please wait 30 seconds and try again.")
        elif response.status_code != 200:
            raise ValueError(f"API error {response.status_code}: {response.text[:200]}")

        data = response.json()
        raw = data["choices"][0]["message"]["content"].strip()

        raw = re.sub(r"^```json\s*", "", raw)
        raw = re.sub(r"^```\s*",     "", raw)
        raw = re.sub(r"\s*```$",     "", raw)

        json_match = re.search(r'\{.*\}', raw, re.DOTALL)
        if json_match:
            raw = json_match.group()

        result = json.loads(raw)

        defaults = {
            "ats_score": 0, "match_score": 0, "matched_skills": [],
            "missing_skills": [], "strengths": [], "improvements": [],
            "keyword_suggestions": [], "experience_gap": "",
            "education_match": "", "overall_summary": "", "quick_wins": []
        }
        for key, default in defaults.items():
            result.setdefault(key, default)

        result["ats_score"]   = max(0, min(100, int(result["ats_score"])))
        result["match_score"] = max(0, min(100, int(result["match_score"])))

        return result

    except json.JSONDecodeError:
        raise ValueError("AI returned an invalid response. Try again or switch to a different model.")
    except requests.Timeout:
        raise ValueError("Request timed out. Try a faster model like Gemini 2.0 Flash.")
    except ValueError:
        raise
    except Exception as e:
        raise ValueError(f"Analysis failed: {str(e)}")


def get_score_color(score: int) -> str:
    if score >= 75: return "#00C851"
    elif score >= 50: return "#ffbb33"
    else: return "#ff4444"


def get_score_label(score: int) -> str:
    if score >= 80: return "Excellent ‚úÖ"
    elif score >= 65: return "Good üëç"
    elif score >= 50: return "Fair ‚ö†Ô∏è"
    else: return "Needs Work ‚ùå"